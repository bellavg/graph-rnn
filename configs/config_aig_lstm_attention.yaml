# Config file for LSTM node and edge models (WITH Attention) - CORRECTED
data:
  dataset_type: 'aig-directed-multiclass'
  graph_file: 'dataset/inputs8_outputs8max_nodes128max.pkl' # CHECK PATH
  use_bfs: false
  max_graphs: null

model:
  mode: 'directed-multiclass'
  use_lstm: true                  # Use LSTM
  use_attention: true             # Use Attention
  edge_model: 'attention_rnn'     # Use Attention EdgeLSTM (matched with 'attention_rnn' in updated setup_models)

  GraphAttentionLSTM:             # Parameters for GraphLevelAttentionLSTM
    embedding_size: 384
    hidden_size: 768
    num_layers: 3
    edge_feature_len: 3           # <-- Define explicitly here
    attention_heads: 8
    attention_dropout: 0.1
    output_size: 256              # For EdgeAttentionLSTM input

  EdgeAttentionLSTM:              # Parameters for EdgeAttentionLSTM
    embedding_size: 128
    hidden_size: 256              # Matches GraphAttentionLSTM.output_size
    num_layers: 4
    edge_feature_len: 3           # <-- Define explicitly here
    attention_heads: 4
    attention_dropout: 0.1

  # --- Unused/Ignored Sections ---
  # GraphLSTM: ...
  # EdgeLSTM: ...
  # GraphRNN: ...
  # EdgeRNN: ...
  # EdgeMLP: ...

train:
  batch_size: 32
  lr: 0.0005
  steps: 50000
  print_iter: 100
  checkpoint_iter: 5000
  checkpoint_dir: 'lstm_attn_checkpoints'
  log_dir: 'lstm_attn_logs'
  lr_schedule_milestones: [10000, 20000, 30000, 40000]
  lr_schedule_gamma: 0.3