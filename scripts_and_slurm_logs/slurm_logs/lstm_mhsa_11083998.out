============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Using config file: configs/config_aig_lstm_attention.yaml
Loaded config:
data:
  dataset_type: aig-directed-multiclass
  graph_file: dataset/final_data.pkl
  use_bfs: false
  max_graphs: null
model:
  mode: directed-multiclass
  use_lstm: true
  use_attention: true
  edge_model: attention_rnn
  GraphAttentionLSTM:
    embedding_size: 384
    hidden_size: 768
    num_layers: 3
    edge_feature_len: 3
    attention_heads: 8
    attention_dropout: 0.1
    output_size: 256
  EdgeAttentionLSTM:
    embedding_size: 128
    hidden_size: 256
    num_layers: 4
    edge_feature_len: 3
    attention_heads: 4
    attention_dropout: 0.1
train:
  batch_size: 32
  lr: 0.0001
  steps: 75000
  print_iter: 100
  checkpoint_iter: 7500
  checkpoint_dir: checkpoints/checkpoints_lstm_mhsa
  log_file: train_results/logs_lstm_mhsa

Computing maximum node count from dataset...
Maximum node count: 89
Computing maximum level from dataset...
Calculated max level 18 from 37000 valid graphs
Maximum level: 18
Loading AIG graphs from dataset/final_data.pkl...
Limited to 30000 graphs for processing.
Preprocessing graphs...
Graph preprocessing complete. 30000 graphs processed, 0 skipped.
Maximum node count in processed dataset: 89
INFO: Topological Sort mode. Effective input size (m_internal): 88
Calculating node levels...
Maximum node level across dataset: 18
Calculating edge type counts for class weighting...
Calculating weights based on 27000 training graphs...
Total edge slots considered for weights: 98341408
Raw edge counts: {0: 96753923, 1: 959297, 2: 628188}
Calculated edge weights (Inverse Frequency): [0.011724252253770828, 1.1824986934661865, 1.8057770729064941]
Dataset ready: 27000 graphs (training split).
Total available graphs: 30000
Training graphs: 27000 (limited by split ratio)
Testing graphs: 3000
Ordering: Topological Sort
Dataset initialized with 27000 training graphs
Final statistics - Max node count: 89, Max level: 18
INFO: Using Topological Sort mode. Effective input/output size (max_nodes-1): 88
INFO: GraphLevelAttentionLSTM using level embedding up to level 18
INFO: Using GraphLevelAttentionLSTM for node level.
Selected EdgeLevelAttentionLSTM model.
Setting up CrossEntropyLoss for 3 edge classes.
Applying edge class weights: [0.011724252253770828, 1.1824986934661865, 1.8057770729064941]
Logger initialized. Logging to train_results/logs_lstm_mhsa
Logger initialized. Writing to: train_results/logs_lstm_mhsa
[100/75000] loss=0.9922 lr=1.0E-04 time/iter=0.144s eta=2:59:44
[200/75000] loss=0.9417 lr=1.0E-04 time/iter=0.140s eta=2:55:07
[300/75000] loss=0.9202 lr=1.0E-04 time/iter=0.140s eta=2:53:53
[400/75000] loss=0.9057 lr=1.0E-04 time/iter=0.139s eta=2:52:44
[500/75000] loss=0.8946 lr=1.0E-04 time/iter=0.139s eta=2:52:22
[600/75000] loss=0.8587 lr=1.0E-04 time/iter=0.139s eta=2:52:19
[700/75000] loss=0.8166 lr=1.0E-04 time/iter=0.139s eta=2:52:00
[800/75000] loss=0.7718 lr=1.0E-04 time/iter=0.139s eta=2:51:55
Epoch 1 complete. Average loss: 0.7526
[900/75000] loss=0.4008 lr=1.0E-04 time/iter=0.139s eta=2:51:38
[1000/75000] loss=0.3774 lr=1.0E-04 time/iter=0.139s eta=2:51:13
[1100/75000] loss=0.3673 lr=1.0E-04 time/iter=0.139s eta=2:50:54
[1200/75000] loss=0.3581 lr=1.0E-04 time/iter=0.139s eta=2:50:46
[1300/75000] loss=0.3490 lr=1.0E-04 time/iter=0.139s eta=2:50:25
[1400/75000] loss=0.3432 lr=1.0E-04 time/iter=0.139s eta=2:50:09
[1500/75000] loss=0.3353 lr=1.0E-04 time/iter=0.139s eta=2:49:55
[1600/75000] loss=0.3270 lr=1.0E-04 time/iter=0.139s eta=2:49:34
Epoch 2 complete. Average loss: 0.3198
[1700/75000] loss=0.2516 lr=1.0E-04 time/iter=0.139s eta=2:49:24
[1800/75000] loss=0.2396 lr=1.0E-04 time/iter=0.139s eta=2:49:09
[1900/75000] loss=0.2306 lr=1.0E-04 time/iter=0.139s eta=2:48:49
[2000/75000] loss=0.2234 lr=1.0E-04 time/iter=0.139s eta=2:48:33
[2100/75000] loss=0.2169 lr=1.0E-04 time/iter=0.139s eta=2:48:20
[2200/75000] loss=0.2097 lr=1.0E-04 time/iter=0.139s eta=2:48:08
[2300/75000] loss=0.2039 lr=1.0E-04 time/iter=0.139s eta=2:47:56
[2400/75000] loss=0.1989 lr=1.0E-04 time/iter=0.139s eta=2:47:42
[2500/75000] loss=0.1938 lr=1.0E-04 time/iter=0.139s eta=2:47:23
Epoch 3 complete. Average loss: 0.1925
[2600/75000] loss=0.1537 lr=1.0E-04 time/iter=0.139s eta=2:47:08
[2700/75000] loss=0.1516 lr=1.0E-04 time/iter=0.139s eta=2:46:55
[2800/75000] loss=0.1497 lr=1.0E-04 time/iter=0.138s eta=2:46:39
[2900/75000] loss=0.1493 lr=1.0E-04 time/iter=0.138s eta=2:46:22
[3000/75000] loss=0.1475 lr=1.0E-04 time/iter=0.138s eta=2:46:09
[3100/75000] loss=0.1459 lr=1.0E-04 time/iter=0.138s eta=2:45:53
[3200/75000] loss=0.1442 lr=1.0E-04 time/iter=0.138s eta=2:45:39
[3300/75000] loss=0.1431 lr=1.0E-04 time/iter=0.138s eta=2:45:24
Epoch 4 complete. Average loss: 0.1422
[3400/75000] loss=0.1304 lr=9.9E-05 time/iter=0.138s eta=2:45:10
[3500/75000] loss=0.1290 lr=9.9E-05 time/iter=0.138s eta=2:44:53
[3600/75000] loss=0.1284 lr=9.9E-05 time/iter=0.138s eta=2:44:43
[3700/75000] loss=0.1276 lr=9.9E-05 time/iter=0.138s eta=2:44:30
[3800/75000] loss=0.1269 lr=9.9E-05 time/iter=0.138s eta=2:44:15
[3900/75000] loss=0.1258 lr=9.9E-05 time/iter=0.138s eta=2:44:03
[4000/75000] loss=0.1248 lr=9.9E-05 time/iter=0.138s eta=2:43:52
[4100/75000] loss=0.1240 lr=9.9E-05 time/iter=0.138s eta=2:43:35
[4200/75000] loss=0.1231 lr=9.9E-05 time/iter=0.138s eta=2:43:17
Epoch 5 complete. Average loss: 0.1230
[4300/75000] loss=0.1191 lr=9.9E-05 time/iter=0.138s eta=2:43:01
[4400/75000] loss=0.1171 lr=9.9E-05 time/iter=0.138s eta=2:42:47
[4500/75000] loss=0.1176 lr=9.9E-05 time/iter=0.138s eta=2:42:35
[4600/75000] loss=0.1161 lr=9.9E-05 time/iter=0.138s eta=2:42:21
[4700/75000] loss=0.1154 lr=9.9E-05 time/iter=0.138s eta=2:42:07
[4800/75000] loss=0.1146 lr=9.9E-05 time/iter=0.138s eta=2:41:54
[4900/75000] loss=0.1140 lr=9.9E-05 time/iter=0.138s eta=2:41:42
[5000/75000] loss=0.1134 lr=9.9E-05 time/iter=0.138s eta=2:41:29
Epoch 6 complete. Average loss: 0.1134
[5100/75000] loss=0.1205 lr=9.9E-05 time/iter=0.138s eta=2:41:13
[5200/75000] loss=0.1132 lr=9.9E-05 time/iter=0.138s eta=2:40:59
[5300/75000] loss=0.1099 lr=9.9E-05 time/iter=0.138s eta=2:40:44
[5400/75000] loss=0.1093 lr=9.9E-05 time/iter=0.138s eta=2:40:32
[5500/75000] loss=0.1087 lr=9.9E-05 time/iter=0.138s eta=2:40:19
[5600/75000] loss=0.1077 lr=9.9E-05 time/iter=0.138s eta=2:40:04
[5700/75000] loss=0.1072 lr=9.9E-05 time/iter=0.138s eta=2:39:51
[5800/75000] loss=0.1066 lr=9.9E-05 time/iter=0.138s eta=2:39:36
[5900/75000] loss=0.1058 lr=9.8E-05 time/iter=0.138s eta=2:39:22
Epoch 7 complete. Average loss: 0.1057
[6000/75000] loss=0.1033 lr=9.8E-05 time/iter=0.138s eta=2:39:09
[6100/75000] loss=0.1012 lr=9.8E-05 time/iter=0.138s eta=2:38:55
[6200/75000] loss=0.1003 lr=9.8E-05 time/iter=0.138s eta=2:38:42
[6300/75000] loss=0.0991 lr=9.8E-05 time/iter=0.138s eta=2:38:29
[6400/75000] loss=0.0988 lr=9.8E-05 time/iter=0.138s eta=2:38:14
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 11083998 ON gcn14 CANCELLED AT 2025-04-08T14:25:36 ***
slurmstepd: error: *** STEP 11083998.0 ON gcn14 CANCELLED AT 2025-04-08T14:25:36 ***

JOB STATISTICS
==============
Job ID: 11083998
Cluster: snellius
User/Group: igardner1/igardner1
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:18:13
CPU Efficiency: 5.49% of 05:32:06 core-walltime
Job Wall-clock time: 00:18:27
Memory Utilized: 7.58 GB
Memory Efficiency: 6.32% of 120.00 GB (120.00 GB/node)
